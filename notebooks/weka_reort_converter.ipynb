{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/gianluca/Documents/dev/irony-detection/reports/weka/no-bow'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weka_path = 'weka/no-bow'\n",
    "# Get project root\n",
    "path = !pwd\n",
    "report_path = '{}/{}/{}'.format('/'.join(path[0].split('/')[:-1]), 'reports', weka_path)\n",
    "report_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_report(path_file):\n",
    "\twith open(path_file) as file:\n",
    "\t\tfile_content = file.readlines()\n",
    "\treturn [line.strip() for line in file_content]\n",
    "\n",
    "def extract_name(file_path):\n",
    "\tfilename = file_path.split('/')[-1]\n",
    "\tfeatures = '-'.join(filename.split('.')[0].split('-')[1:])\n",
    "\treturn features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def extract_report_data(file_content):\n",
    "\tdict_report = dict()\n",
    "\t# Extract dict report\n",
    "\tdict_report['accuracy'] = float(file_content[3].split()[-2])/100\n",
    "\tdict_report['False'] = extract_report_type(file_content, 16)\n",
    "\tdict_report['True'] = extract_report_type(file_content, 15)\n",
    "\tdict_report['weighted avg'] = extract_report_type(file_content, 17)\n",
    "\t# Build report dict\n",
    "\tdict_data = dict()\n",
    "\tdict_data['report'] = dict_report\n",
    "\tdict_data['confusion-matrix'] = extract_confusion_matrix(file_content)\n",
    "\t# Return dict\n",
    "\treturn dict_data\n",
    "\n",
    "def extract_report_type(file_content, line):\n",
    "\tsplit_line = file_content[line].split()\n",
    "\t# Support\n",
    "\tif line == 16:\n",
    "\t\tsupport = 30000\n",
    "\telif line == 15:\n",
    "\t\tsupport = 10000\n",
    "\telse:\n",
    "\t\tsplit_line = split_line[2:]\n",
    "\t\tsupport = 40000\n",
    "\t# Split line\n",
    "\treport_dict = extract_line(split_line)\n",
    "\treport_dict['support'] = float(support)\n",
    "\t\n",
    "\treturn report_dict\n",
    "\t\n",
    "def extract_line(line):\n",
    "\treport_dict = dict()\n",
    "\treport_dict['precision'] = float(line[2])\n",
    "\treport_dict['recall'] = float(line[3])\n",
    "\treport_dict['f1-score'] = float(line[4])\n",
    "\treturn report_dict\n",
    "\n",
    "def extract_dict(path_file):\n",
    "\t# Read file content\n",
    "\tfile_content = read_report(path_file)\n",
    "\t# Build dict\n",
    "\tout_dict = dict()\n",
    "\tout_dict['overall'] = extract_report_data(file_content)\n",
    "\tout_dict['features'] = extract_name(path_file)\n",
    "\tout_dict['classifier'] = 'BayesianNetworks'\n",
    "\t# Return dict\n",
    "\treturn out_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def extract_confusion_matrix(file_content):\n",
    "\ttp, fp, *_ = file_content[22].split()\n",
    "\tfn, tn, *_ = file_content[23].split()\n",
    "\t# Create numpy matrix\n",
    "\tmatrix = np.array([[tp, fp], [fn, tn]], dtype=np.float)\n",
    "\t# Swap rows\n",
    "\tout_matrix = np.zeros((2, 2))\n",
    "\tout_matrix[0, :] = matrix[1, :] \n",
    "\tout_matrix[1, :] = matrix[0, :] \n",
    "\t# Swap columns\n",
    "\tout_matrix[0, 0], out_matrix[0, 1] = out_matrix[0, 1], out_matrix[0, 0]\n",
    "\tout_matrix[1, 0], out_matrix[1, 1] = out_matrix[1, 1], out_matrix[1, 0]\n",
    "\t# Return confusion matrix\n",
    "\treturn out_matrix.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save json report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "def dump_dict_report(dict):\n",
    "\tfilename = '{}${}.json'.format(dict['features'], 'BayesianNetworks')\n",
    "\tpath = '{}/json/{}'.format(report_path, filename)\n",
    "\twith open(path, 'w') as fp:\n",
    "\t\tjson.dump(dict, fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/gianluca/Documents/dev/irony-detection/reports/weka/no-bow/text'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-7-31f0a831262b>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mpath_file\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'{}/{}'\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mreport_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfile\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m \u001B[0mfile_list\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlistdir\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'{}/text'\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mreport_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/home/gianluca/Documents/dev/irony-detection/reports/weka/no-bow/text'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "file = 'labeled_matrix-emot.txt'\n",
    "path_file = '{}/{}'.format(report_path, file)\n",
    "\n",
    "file_list = os.listdir('{}/text'.format(report_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate all reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for file in os.listdir('{}/text'.format(report_path)):\n",
    "\t# Get file path\n",
    "\tpath_file = '{}/text/{}'.format(report_path, file)\n",
    "\t# Extract report dict\n",
    "\treport_dict = extract_dict(path_file)\n",
    "\t# Dump dict\n",
    "\tdump_dict_report(report_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}